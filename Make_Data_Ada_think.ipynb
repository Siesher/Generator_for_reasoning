{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "\n",
    "# --- –ù–ê–°–¢–†–û–ô–ö–ò ---\n",
    "# ==============================================================================\n",
    "# –≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∑–≤–æ–ª—è—é—Ç –ª–µ–≥–∫–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –ø–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞.\n",
    "\n",
    "# 1. –í–∞—à–∏ API –∫–ª—é—á–∏ Cerebras\n",
    "# –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏! –ü–æ–ª—É—á–∏—Ç—å –∏—Ö –º–æ–∂–Ω–æ –∑–¥–µ—Å—å: https://cloud.cerebras.ai/platform/org_.../apikeys\n",
    "# –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n",
    "# export CEREBRAS_API_KEY_1=\"cbkey_xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "API_KEYS = []\n",
    "\n",
    "# 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è Cerebras\n",
    "MODEL_NAME_TEACHER = \"qwen-3-235b-a22b\"\n",
    "\n",
    "# 3. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞\n",
    "MAX_WORKERS = 4 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API. –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –ª–∏–º–∏—Ç–æ–≤ API –∏ –≤–∞—à–µ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "# 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö API\n",
    "MAX_RETRIES_PER_KEY = 3 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ —Å –æ–¥–Ω–∏–º –∫–ª—é—á–æ–º –¥–æ –µ–≥–æ —Å–º–µ–Ω—ã\n",
    "RETRY_DELAY = 5         # –ü–∞—É–∑–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏\n",
    "\n",
    "# 5. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "NUM_UNIQUE_QUESTIONS_TO_GENERATE = 400 # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö \"—Ç–µ–º\" –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n",
    "QUESTIONS_BATCH_SIZE = 3               # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –∑–∞ –æ–¥–∏–Ω API-–∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–ø–µ.\n",
    "# –°–∫–æ–ª—å–∫–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º—ã —Ö–æ—Ç–∏–º –ø–æ–ª—É—á–∏—Ç—å –¥–ª—è –ö–ê–ñ–î–û–ì–û —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.\n",
    "# –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ 3, –∏ —É –Ω–∞—Å 3 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (CoT, PoT, SkipThinking), —Ç–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –±—É–¥–µ—Ç –ø–æ 1 –ø—Ä–∏–º–µ—Ä—É –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.\n",
    "NUM_REASONING_STRATEGIES_PER_QUESTION = 6 \n",
    "\n",
    "# 6. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π\n",
    "WORDS_IN_REASONING = \"100-200\" # –û–∂–∏–¥–∞–µ–º—ã–π –æ–±—ä–µ–º \"–º—ã—Å–ª–µ–π\" (chain_of_thought) –≤ —Å–ª–æ–≤–∞—Ö –¥–ª—è CoT/PoT.\n",
    "WORDS_IN_CHUNK = \"30-50\"       # –û–∂–∏–¥–∞–µ–º—ã–π –æ–±—ä–µ–º —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º \"–±–ª–æ–∫–µ –º—ã—Å–ª–∏\" –¥–ª—è Skip-Thinking.\n",
    "\n",
    "# 7. –§–∞–π–ª –≤—ã–≤–æ–¥–∞\n",
    "OUTPUT_DATASET_FILE = \"qwen3_adaptive_reasoning_dataset.jsonl\"\n",
    "\n",
    "# --- –ü–†–û–ú–ü–¢–´ ---\n",
    "# ==============================================================================\n",
    "# –ó–¥–µ—Å—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤ –∏ —Ç–∏–ø–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.\n",
    "\n",
    "# –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤\n",
    "QUESTION_GENERATOR_PROMPT = \"\"\"\n",
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–∏–¥—É–º–∞—Ç—å {count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏ —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —Ç—Ä–µ–±—É—é—â–∏—Ö –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞.\n",
    "–í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–∑ —Å–ª–µ–¥—É—é—â–µ–π –æ–±–ª–∞—Å—Ç–∏: {topic}.\n",
    "–ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–∏–º–µ–Ω–∏–º–æ –∫ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–≤—Ç–æ—Ä—è—é—Ç –æ–¥–Ω—É –∏ —Ç—É –∂–µ –±–∞–∑–æ–≤—É—é –∏–¥–µ—é, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç **—Ä–∞–∑–Ω—ã–µ —á–∏—Å–ª–∞, —É—Å–ª–æ–≤–∏—è, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã**, —á—Ç–æ–±—ã –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å –æ—Å—Ç–∞–≤–∞–ª—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–º, –Ω–æ –ø—Ä–æ–≤–µ—Ä—è–ª —Å—Ö–æ–∂–∏–π —Ç–∏–ø —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.\n",
    "\n",
    "–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –≤ –≤–∏–¥–µ –≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON-–º–∞—Å—Å–∏–≤–∞ —Å—Ç—Ä–æ–∫. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –¥—Ä—É–≥–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏ –ø–æ—Å–ª–µ JSON.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä:\n",
    "[\"–ö–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –ø—Ä–∏–º–µ—Ä–Ω—ã–π –≤–µ—Å –æ–±–ª–∞–∫–∞?\", \"–ï—Å–ª–∏ –±—ã —É —Ç–µ–Ω–∏ –±—ã–ª –≤–µ—Å, —á—Ç–æ –±—ã –ø–æ–≤–ª–∏—è–ª–æ –Ω–∞ –µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è?\", \"–ï—Å–ª–∏ –≤ —Å–∞–¥—É 10 —è–±–ª–æ–Ω—å, –∏ –∫–∞–∂–¥–∞—è –¥–∞–µ—Ç –ø–æ 20 –∫–≥ —è–±–ª–æ–∫, —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ —è–±–ª–æ–∫ –±—É–¥–µ—Ç —Å–æ–±—Ä–∞–Ω–æ?\", \"–ï—Å–ª–∏ –≤ —Å–∞–¥—É 15 —è–±–ª–æ–Ω—å, –∏ –∫–∞–∂–¥–∞—è –¥–∞–µ—Ç –ø–æ 15 –∫–≥ —è–±–ª–æ–∫, —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ —è–±–ª–æ–∫ –±—É–¥–µ—Ç —Å–æ–±—Ä–∞–Ω–æ?\"]\n",
    "\n",
    "–¢–≤–æ–π JSON-–º–∞—Å—Å–∏–≤ —Å {count} –≤–æ–ø—Ä–æ—Å–∞–º–∏:\n",
    "\"\"\"\n",
    "\n",
    "# –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Chain-of-Thought (CoT) —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π\n",
    "REASONING_SOLVER_PROMPT_COT = \"\"\"\n",
    "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, —Å–ø–æ—Å–æ–±–Ω–∞—è –∫ –≥–ª—É–±–æ–∫–∏–º –ø–æ—à–∞–≥–æ–≤—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º. –¢–≤–æ—è —Ü–µ–ª—å ‚Äî —Ä–µ—à–∏—Ç—å –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∑–∞–¥–∞—á—É, –ø–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω–∏–≤ —Å–≤–æ–π –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (Chain-of-Thought).\n",
    "–¢—ã –¥–æ–ª–∂–µ–Ω —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.\n",
    "\n",
    "–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:\n",
    "–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º JSON-–æ–±—ä–µ–∫—Ç–æ–º —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏: \"question\", \"chain_of_thought\", \"answer\", \"thought_type\".\n",
    "\n",
    "1.  **`chain_of_thought`**: –ó–¥–µ—Å—å —Ç—ã –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –µ–≥–æ –ª–æ–≥–∏—á–µ—Å–∫–∏, —à–∞–≥ –∑–∞ —à–∞–≥–æ–º. –ù–∞—á–Ω–∏ —Å –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–ø—Ä–æ—Å–∞, –∑–∞—Ç–µ–º –æ–ø–∏—à–∏ –ø–ª–∞–Ω —Ä–µ—à–µ–Ω–∏—è –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏–∑–ª–æ–∂–∏ —Å–≤–æ–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –í–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ {WORDS_IN_REASONING} —Å–ª–æ–≤.\n",
    "2.  **`answer`**: –ó–¥–µ—Å—å —É–∫–∞–∂–∏ –¢–û–õ–¨–ö–û –∫–æ–Ω–µ—á–Ω—ã–π, —á–µ—Ç–∫–∏–π –∏ —Å–∂–∞—Ç—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π.\n",
    "3.  **`thought_type`**: –í—Å–µ–≥–¥–∞ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π –∑–Ω–∞—á–µ–Ω–∏–µ \"CoT\" –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.\n",
    "\n",
    "–í–æ–ø—Ä–æ—Å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è:\n",
    "{question}\n",
    "\n",
    "–¢–≤–æ–π JSON-–æ—Ç–≤–µ—Ç:\n",
    "\"\"\"\n",
    "\n",
    "# –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Program-of-Thought (PoT) —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π\n",
    "REASONING_SOLVER_PROMPT_POT = \"\"\"\n",
    "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, —Å–ø–æ—Å–æ–±–Ω–∞—è –∫ –≥–ª—É–±–æ–∫–∏–º –ø–æ—à–∞–≥–æ–≤—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º. –¢–≤–æ—è —Ü–µ–ª—å ‚Äî —Ä–µ—à–∏—Ç—å –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∑–∞–¥–∞—á—É, –ø–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω–∏–≤ —Å–≤–æ–π –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∫–æ–¥ (Python) –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏.\n",
    "–¢—ã –¥–æ–ª–∂–µ–Ω —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.\n",
    "\n",
    "–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:\n",
    "–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º JSON-–æ–±—ä–µ–∫—Ç–æ–º —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏: \"question\", \"chain_of_thought\", \"answer\", \"thought_type\".\n",
    "\n",
    "1.  **`chain_of_thought`**: –ó–¥–µ—Å—å —Ç—ã –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –µ–≥–æ –ª–æ–≥–∏—á–µ—Å–∫–∏, —à–∞–≥ –∑–∞ —à–∞–≥–æ–º. –ù–∞—á–Ω–∏ —Å –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–ø—Ä–æ—Å–∞, –∑–∞—Ç–µ–º –æ–ø–∏—à–∏ –ø–ª–∞–Ω —Ä–µ—à–µ–Ω–∏—è, –∑–∞—Ç–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏–∑–ª–æ–∂–∏ —Å–≤–æ–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, **–≤–∫–ª—é—á–∞—è –±–ª–æ–∫–∏ –∫–æ–¥–∞ Python –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π**. –ò—Å–ø–æ–ª—å–∑—É–π Markdown –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –∫–æ–¥–∞. –í–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ {WORDS_IN_REASONING} —Å–ª–æ–≤.\n",
    "2.  **`answer`**: –ó–¥–µ—Å—å —É–∫–∞–∂–∏ –¢–û–õ–¨–ö–û –∫–æ–Ω–µ—á–Ω—ã–π, —á–µ—Ç–∫–∏–π –∏ —Å–∂–∞—Ç—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π.\n",
    "3.  **`thought_type`**: –í—Å–µ–≥–¥–∞ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π –∑–Ω–∞—á–µ–Ω–∏–µ \"PoT\" –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä `chain_of_thought` –¥–ª—è –∑–∞–¥–∞—á–∏: \"–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 5 * 8 + 3?\"\n",
    "\"–î–ª—è —Ä–µ—à–µ–Ω–∏—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ —è —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—é —É–º–Ω–æ–∂–µ–Ω–∏–µ, –∞ –∑–∞—Ç–µ–º —Å–ª–æ–∂–µ–Ω–∏–µ.\n",
    "```python\n",
    "result = 5 * 8\n",
    "```\n",
    "–ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–º–Ω–æ–∂–µ–Ω–∏—è —Ä–∞–≤–µ–Ω 40. –¢–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–ª—é 3:\n",
    "```python\n",
    "final_result = 40 + 3\n",
    "```\n",
    "–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - 43.\"\n",
    "\n",
    "–í–æ–ø—Ä–æ—Å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è:\n",
    "{question}\n",
    "\n",
    "–¢–≤–æ–π JSON-–æ—Ç–≤–µ—Ç:\n",
    "\"\"\"\n",
    "\n",
    "# –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Skip-Thinking —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (—Å –±–ª–æ–∫–∞–º–∏)\n",
    "REASONING_SOLVER_PROMPT_SKIP_THINKING = \"\"\"\n",
    "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, —Å–ø–æ—Å–æ–±–Ω–∞—è –∫ –≥–ª—É–±–æ–∫–∏–º –ø–æ—à–∞–≥–æ–≤—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º. –¢–≤–æ—è —Ü–µ–ª—å ‚Äî —Ä–µ—à–∏—Ç—å –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∑–∞–¥–∞—á—É, –ø–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω–∏–≤ —Å–≤–æ–π –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, —Ä–∞–∑–±–∏–≤–∞—è –µ–≥–æ –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ, –∞—Ç–æ–º–∞—Ä–Ω—ã–µ \"–±–ª–æ–∫–∏ –º—ã—Å–ª–µ–π\".\n",
    "–ö–∞–∂–¥—ã–π –±–ª–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–∫–ª—é—á–µ–Ω –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏: <chunk_start> –∏ <chunk_end>.\n",
    "–í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞, –ø–æ—Å–ª–µ <chunk_end>, —Ç—ã —Ç–∞–∫–∂–µ –¥–æ–ª–∂–µ–Ω —É–∫–∞–∑–∞—Ç—å –æ–¥–∏–Ω –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –º–∞—Ä–∫–µ—Ä–æ–≤:\n",
    "- <continue_thinking>: –µ—Å–ª–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–∞–ª—å–Ω–µ–π—à–µ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ.\n",
    "- <end_of_thought>: –µ—Å–ª–∏ —Ç—ã —Å—á–∏—Ç–∞–µ—à—å, —á—Ç–æ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –±–ª–æ–∫–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –ø–µ—Ä–µ–π—Ç–∏ –∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É –æ—Ç–≤–µ—Ç—É.\n",
    "\n",
    "–¢—ã –¥–æ–ª–∂–µ–Ω —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.\n",
    "\n",
    "–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:\n",
    "–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º JSON-–æ–±—ä–µ–∫—Ç–æ–º —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏: \"question\", \"chain_of_thought\", \"answer\", \"thought_type\".\n",
    "\n",
    "1.  **`chain_of_thought`**: –ó–¥–µ—Å—å —Ç—ã –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–π –Ω–∞ –±–ª–æ–∫–∏. –ü—Ä–∏–º–µ—Ä:\n",
    "    <chunk_start>\n",
    "    [–®–∞–≥ 1 —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –î–ª–∏–Ω–∞ –ø—Ä–∏–º–µ—Ä–Ω–æ {WORDS_IN_CHUNK} —Å–ª–æ–≤.]\n",
    "    </chunk_end><continue_thinking>\n",
    "    <chunk_start>\n",
    "    [–®–∞–≥ 2 —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –î–ª–∏–Ω–∞ –ø—Ä–∏–º–µ—Ä–Ω–æ {WORDS_IN_CHUNK} —Å–ª–æ–≤.]\n",
    "    </chunk_end><end_of_thought>\n",
    "    –ò–ª–∏, –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –∑–∞–¥–∞—á–∏:\n",
    "    <chunk_start>\n",
    "    [–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –±–ª–æ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –î–ª–∏–Ω–∞ –ø—Ä–∏–º–µ—Ä–Ω–æ {WORDS_IN_CHUNK} —Å–ª–æ–≤.]\n",
    "    </chunk_end><end_of_thought>\n",
    "    –í–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
    "2.  **`answer`**: –ó–¥–µ—Å—å —É–∫–∞–∂–∏ –¢–û–õ–¨–ö–û –∫–æ–Ω–µ—á–Ω—ã–π, —á–µ—Ç–∫–∏–π –∏ —Å–∂–∞—Ç—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π.\n",
    "3.  **`thought_type`**: –í—Å–µ–≥–¥–∞ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π –∑–Ω–∞—á–µ–Ω–∏–µ \"SkipThinking\" –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.\n",
    "\n",
    "–í–æ–ø—Ä–æ—Å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è:\n",
    "{question}\n",
    "\n",
    "–¢–≤–æ–π JSON-–æ—Ç–≤–µ—Ç:\n",
    "\"\"\"\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤\n",
    "REASONING_STRATEGIES = {\n",
    "    \"CoT\": REASONING_SOLVER_PROMPT_COT,\n",
    "    \"PoT\": REASONING_SOLVER_PROMPT_POT,\n",
    "    \"SkipThinking\": REASONING_SOLVER_PROMPT_SKIP_THINKING,\n",
    "}\n",
    "\n",
    "# –¢–µ–º—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤\n",
    "QUESTION_TOPICS = [\n",
    "    \"–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–≥–∞–¥–∫–∏\", \"–ø—Ä–æ—Å—Ç–∞—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞\", \"–±—ã—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –ª–æ–≥–∏–∫—É\",\n",
    "    \"–∑–∞–¥–∞—á–∏ –Ω–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ\", \"—Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–¥–æ–∫—Å—ã\", \"–∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Ü–µ–Ω–∫—É\",\n",
    "    \"–∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏\", \"—ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏\", \"–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –≥–∏–ø–æ—Ç–µ–∑—ã\",\n",
    "    \"—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏\", \"–∑–∞–¥–∞—á–∏ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å\", \"–Ω–∞—É—á–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏\",\n",
    "    \"–≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏\", \"—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–∞—Å—á–µ—Ç—ã\", \"–∑–∞–¥–∞—á–∏ –Ω–∞ –≤—Ä–µ–º—è\",\n",
    "    \"–∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ–∏—è (–æ—Å–Ω–æ–≤—ã)\", \"–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (–∫–æ–Ω—Ü–µ–ø—Ü–∏–∏)\", \"–±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã\"\n",
    "]\n",
    "\n",
    "# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –ò –£–ü–†–ê–í–õ–ï–ù–ò–ï –ö–õ–ò–ï–ù–¢–û–ú ---\n",
    "# ==============================================================================\n",
    "\n",
    "current_key_index = 0\n",
    "cerebras_client = None\n",
    "\n",
    "def get_client():\n",
    "    \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–ª–∏–µ–Ω—Ç Cerebras —Å —Ç–µ–∫—É—â–∏–º API-–∫–ª—é—á–æ–º.\"\"\"\n",
    "    global cerebras_client\n",
    "    if not API_KEYS or not API_KEYS[0].strip():\n",
    "        raise ValueError(\"API –∫–ª—é—á–∏ Cerebras –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ —Å–ø–∏—Å–∫–µ API_KEYS. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –∏—Ö.\")\n",
    "    \n",
    "    api_key = API_KEYS[current_key_index]\n",
    "    if not api_key.strip() or \"cbkey_xxxxxxxx\" in api_key: # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π –∏–ª–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä\n",
    "        raise ValueError(f\"API –∫–ª—é—á Cerebras #{current_key_index + 1} –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–º–µ–Ω–∏—Ç–µ –µ–≥–æ.\")\n",
    "    \n",
    "    cerebras_client = Cerebras(api_key=api_key)\n",
    "    return cerebras_client\n",
    "\n",
    "def switch_to_next_key():\n",
    "    \"\"\"–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π API-–∫–ª—é—á –≤ —Å–ø–∏—Å–∫–µ, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã.\"\"\"\n",
    "    global current_key_index\n",
    "    current_key_index += 1\n",
    "    if current_key_index < len(API_KEYS):\n",
    "        tqdm.write(f\"‚ö†Ô∏è [INFO] –õ–∏–º–∏—Ç –¥–ª—è –∫–ª—é—á–∞ –∏—Å—á–µ—Ä–ø–∞–Ω –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –∫–ª—é—á #{current_key_index + 1}.\")\n",
    "        get_client() # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç —Å –Ω–æ–≤—ã–º –∫–ª—é—á–æ–º\n",
    "        return True\n",
    "    else:\n",
    "        tqdm.write(\"‚ùå [ERROR] –í—Å–µ API –∫–ª—é—á–∏ Cerebras –∏—Å—á–µ—Ä–ø–∞–Ω—ã. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å.\")\n",
    "        return False\n",
    "        \n",
    "def safe_json_parse(response_content: str) -> dict | list | None:\n",
    "    \"\"\"\n",
    "    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ —Å—Ç—Ä–æ–∫–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω –æ–∫—Ä—É–∂–µ–Ω –¥—Ä—É–≥–∏–º —Ç–µ–∫—Å—Ç–æ–º.\n",
    "    –ò—â–µ—Ç –ø–µ—Ä–≤—ã–π '{' –∏–ª–∏ '[' –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π '}' –∏–ª–∏ ']'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_brace_idx = response_content.find('{')\n",
    "        first_bracket_idx = response_content.find('[')\n",
    "        \n",
    "        start_pos = -1\n",
    "        if first_brace_idx != -1 and first_bracket_idx != -1:\n",
    "            start_pos = min(first_brace_idx, first_bracket_idx)\n",
    "        elif first_brace_idx != -1:\n",
    "            start_pos = first_brace_idx\n",
    "        elif first_bracket_idx != -1:\n",
    "            start_pos = first_bracket_idx\n",
    "        else:\n",
    "            return None # JSON –Ω–µ –Ω–∞–π–¥–µ–Ω\n",
    "\n",
    "        if start_pos == -1: return None \n",
    "\n",
    "        end_char = '}' if response_content[start_pos] == '{' else ']'\n",
    "        end_pos = response_content.rfind(end_char)\n",
    "        \n",
    "        if end_pos == -1 or end_pos < start_pos: return None \n",
    "        \n",
    "        json_str = response_content[start_pos : end_pos + 1]\n",
    "        return json.loads(json_str)\n",
    "        \n",
    "    except (json.JSONDecodeError, IndexError) as e:\n",
    "        tqdm.write(f\"‚ÄºÔ∏è [WARN] –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å JSON. –û—à–∏–±–∫–∞: {e}\\n–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (–Ω–∞—á–∞–ª–æ): {response_content[:200]}...\")\n",
    "        return None\n",
    "\n",
    "# --- –Ø–î–†–û –õ–û–ì–ò–ö–ò: –í–´–ü–û–õ–ù–ï–ù–ò–ï –ó–ê–ü–†–û–°–û–í ---\n",
    "# ==============================================================================\n",
    "\n",
    "def execute_api_call(prompt: str, task_description: str, model_name: str):\n",
    "    \"\"\"\n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç API-–∑–∞–ø—Ä–æ—Å –∫ Cerebras —Å –∞–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –∫–ª—é—á–µ–π –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.\n",
    "    \"\"\"\n",
    "    global cerebras_client\n",
    "    \n",
    "    current_attempt_with_key = 0\n",
    "    while current_key_index < len(API_KEYS):\n",
    "        if current_attempt_with_key >= MAX_RETRIES_PER_KEY:\n",
    "            if not switch_to_next_key():\n",
    "                return None \n",
    "            current_attempt_with_key = 0 \n",
    "        \n",
    "        try:\n",
    "            chat_completion = cerebras_client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=model_name,\n",
    "                temperature=0.7, \n",
    "                max_tokens=2048, \n",
    "            )\n",
    "            return chat_completion.choices[0].message.content.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            current_attempt_with_key += 1\n",
    "            tqdm.write(f\"‚ÄºÔ∏è [WARN] –û—à–∏–±–∫–∞ '{task_description}' (–∫–ª—é—á #{current_key_index + 1}, –ø–æ–ø—ã—Ç–∫–∞ {current_attempt_with_key}/{MAX_RETRIES_PER_KEY}): {e}\")\n",
    "            time.sleep(RETRY_DELAY) \n",
    "        \n",
    "    return None \n",
    "\n",
    "def generate_questions_batch(count: int, topic: str) -> list[str]:\n",
    "    \"\"\"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä—Ç–∏—é —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ.\"\"\"\n",
    "    prompt = QUESTION_GENERATOR_PROMPT.format(count=count, topic=topic)\n",
    "    response_content = execute_api_call(prompt, f\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ '{topic}'\", MODEL_NAME_TEACHER)\n",
    "    \n",
    "    if not response_content:\n",
    "        return []\n",
    "    \n",
    "    questions = safe_json_parse(response_content)\n",
    "    return [q.strip() for q in questions if isinstance(q, str) and q.strip()] if isinstance(questions, list) else []\n",
    "\n",
    "def generate_reasoning_example(question: str, strategy_type: str, prompt_template: str) -> dict | None:\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –æ—Ç–≤–µ—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞, –∏—Å–ø–æ–ª—å–∑—É—è –∑–∞–¥–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é.\n",
    "    –í–∫–ª—é—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ thought_type –¥–ª—è –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ Adaptive Thinking.\n",
    "    \"\"\"\n",
    "    prompt_format_args = {\n",
    "        \"question\": question,\n",
    "        \"WORDS_IN_REASONING\": WORDS_IN_REASONING\n",
    "    }\n",
    "    if strategy_type == \"SkipThinking\":\n",
    "        prompt_format_args[\"WORDS_IN_CHUNK\"] = WORDS_IN_CHUNK\n",
    "\n",
    "    prompt = prompt_template.format(**prompt_format_args)\n",
    "    response_content = execute_api_call(prompt, f\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è {strategy_type} –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question[:50]}...'\", MODEL_NAME_TEACHER)\n",
    "\n",
    "    if not response_content:\n",
    "        return None\n",
    "        \n",
    "    data_from_model = safe_json_parse(response_content)\n",
    "    \n",
    "    required_keys = [\"question\", \"chain_of_thought\", \"answer\", \"thought_type\"]\n",
    "    if not isinstance(data_from_model, dict) or not all(key in data_from_model for key in required_keys):\n",
    "        tqdm.write(f\"‚ÄºÔ∏è [WARN] –í –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–ª—é—á–∏ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è {strategy_type}. –ü—Ä–æ–ø—É—Å–∫–∞—é. –û—Ç–≤–µ—Ç: {response_content[:100]}...\")\n",
    "        return None\n",
    "\n",
    "    data_from_model['thought_type'] = data_from_model.get('thought_type', strategy_type)\n",
    "\n",
    "    assistant_content = (\n",
    "        f\"<thought_type>{data_from_model['thought_type']}</thought_type>\\n\"\n",
    "        f\"<think>\\n{data_from_model['chain_of_thought']}\\n</think>\\n\" \n",
    "        f\"{data_from_model['answer']}\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": data_from_model[\"question\"]},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# --- –û–°–ù–û–í–ù–û–ô –ö–û–î ---\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É—é—â–∞—è –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    –¥–ª—è –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ Adaptive Thinking –∏ Skip-Thinking.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        get_client() # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞\n",
    "    except ValueError as e:\n",
    "        print(f\"‚ùå [–û–®–ò–ë–ö–ê] {e}\")\n",
    "        return\n",
    "\n",
    "    # --- –≠–¢–ê–ü 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üöÄ –≠–¢–ê–ü 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {NUM_UNIQUE_QUESTIONS_TO_GENERATE} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–º –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é Cerebras...\")\n",
    "    all_unique_questions = set() \n",
    "    \n",
    "    with tqdm(total=NUM_UNIQUE_QUESTIONS_TO_GENERATE, desc=\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–º –≤–æ–ø—Ä–æ—Å–æ–≤\") as pbar:\n",
    "        while len(all_unique_questions) < NUM_UNIQUE_QUESTIONS_TO_GENERATE and current_key_index < len(API_KEYS):\n",
    "            needed = NUM_UNIQUE_QUESTIONS_TO_GENERATE - len(all_unique_questions)\n",
    "            batch_size = min(needed, QUESTIONS_BATCH_SIZE)\n",
    "            \n",
    "            new_questions_batch = generate_questions_batch(batch_size, random.choice(QUESTION_TOPICS))\n",
    "            \n",
    "            if not new_questions_batch:\n",
    "                if current_key_index >= len(API_KEYS) - 1: # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–ª—é—á\n",
    "                    tqdm.write(\"‚ùå [ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –∏ –≤—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.\")\n",
    "                    break\n",
    "                # –ï—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ –Ω–µ –±—ã–ª–æ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤, –Ω–æ –∫–ª—é—á–∏ –µ—â–µ –µ—Å—Ç—å, –¥–µ–ª–∞–µ–º –ø–∞—É–∑—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º\n",
    "                time.sleep(RETRY_DELAY) \n",
    "                continue\n",
    "\n",
    "            prev_count = len(all_unique_questions)\n",
    "            all_unique_questions.update(new_questions_batch) \n",
    "            pbar.update(len(all_unique_questions) - prev_count) \n",
    "            time.sleep(0.5) \n",
    "\n",
    "    unique_questions_list = list(all_unique_questions)\n",
    "    print(f\"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(unique_questions_list)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–º –≤–æ–ø—Ä–æ—Å–æ–≤.\")\n",
    "\n",
    "    if not unique_questions_list:\n",
    "        print(\"–í–æ–ø—Ä–æ—Å—ã –Ω–µ –±—ã–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.\")\n",
    "        return\n",
    "\n",
    "    # --- –≠–¢–ê–ü 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–¥–∞—á –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üß† –≠–¢–ê–ü 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–¥–∞—á –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤...\")\n",
    "    \n",
    "    tasks_for_reasoning = []\n",
    "    strategy_types_list = list(REASONING_STRATEGIES.keys())\n",
    "    \n",
    "    for question in unique_questions_list:\n",
    "        for i in range(NUM_REASONING_STRATEGIES_PER_QUESTION):\n",
    "            # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏. –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –≤–µ—Å–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤.\n",
    "            # –ù–∞–ø—Ä–∏–º–µ—Ä, SkipThinking –∏ CoT –º–æ–≥—É—Ç –±—ã—Ç—å –±–æ–ª–µ–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º–∏.\n",
    "            chosen_strategy_type = random.choices(\n",
    "                strategy_types_list, \n",
    "                weights=[0.2, 0.5, 0.3] if \"SkipThinking\" in strategy_types_list else [0.5, 0.5], # –ü—Ä–∏–º–µ—Ä –≤–µ—Å–æ–≤\n",
    "                k=1\n",
    "            )[0]\n",
    "            chosen_prompt_template = REASONING_STRATEGIES[chosen_strategy_type]\n",
    "            \n",
    "            tasks_for_reasoning.append({\n",
    "                \"question\": question,\n",
    "                \"strategy_type\": chosen_strategy_type,\n",
    "                \"prompt_template\": chosen_prompt_template\n",
    "            })\n",
    "    random.shuffle(tasks_for_reasoning) \n",
    "\n",
    "    print(f\"ÔøΩ –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ {len(tasks_for_reasoning)} –∑–∞–¥–∞—á –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.\")\n",
    "    \n",
    "    # --- –≠–¢–ê–ü 3: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –æ—Ç–≤–µ—Ç–æ–≤ ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üöÄ –≠–¢–ê–ü 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (—Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤) –≤ {MAX_WORKERS} –ø–æ—Ç–æ–∫–æ–≤...\")\n",
    "    \n",
    "    final_samples = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_task = {\n",
    "            executor.submit(generate_reasoning_example, t['question'], t['strategy_type'], t['prompt_template']): t\n",
    "            for t in tasks_for_reasoning\n",
    "        }\n",
    "        \n",
    "        progress_bar = tqdm(as_completed(future_to_task), total=len(tasks_for_reasoning), desc=\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –æ—Ç–≤–µ—Ç–æ–≤\")\n",
    "        \n",
    "        for future in progress_bar:\n",
    "            original_task = future_to_task[future]\n",
    "            try:\n",
    "                result_data = future.result()\n",
    "                if result_data:\n",
    "                    final_samples.append(result_data)\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"‚ùå [ERROR] –û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ '{original_task['question'][:50]}...' ({original_task['strategy_type']}). –û—à–∏–±–∫–∞: {e}\")\n",
    "\n",
    "    # --- –≠–¢–ê–ü 4: –ó–∞–ø–∏—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ñ–∞–π–ª ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üíæ –≠–¢–ê–ü 4: –ó–∞–ø–∏—Å—å {len(final_samples)} —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ñ–∞–π–ª '{OUTPUT_DATASET_FILE}'...\")\n",
    "    \n",
    "    with open(OUTPUT_DATASET_FILE, 'a', encoding='utf-8') as f:\n",
    "        for entry in final_samples:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    # --- –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "    print(f\"–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {OUTPUT_DATASET_FILE}\")\n",
    "    print(f\"–í—Å–µ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(final_samples)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ Adaptive Thinking.\")\n",
    "    if final_samples:\n",
    "        print(\"\\n–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–µ:\")\n",
    "        print(json.dumps(final_samples[0], indent=2, ensure_ascii=False)) \n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3677f",
   "metadata": {},
   "source": [
    "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª–∏–Ω—ã sample-–æ–≤ –ø–æ —Ç–æ–∫–µ–Ω–∞–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d25f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- –ù–ê–°–¢–†–û–ô–ö–ò ---\n",
    "# ==============================================================================\n",
    "# –ò–º—è —Ñ–∞–π–ª–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Å–∫—Ä–∏–ø—Ç–æ–º\n",
    "OUTPUT_DATASET_FILE = \"D:\\Work\\Python\\Parser_for_distil_dataset\\qwen3_adaptive_reasoning_dataset.jsonl\"\n",
    "# –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã\n",
    "HISTOGRAM_OUTPUT_FILE = \"token_length_histogram.png\"\n",
    "\n",
    "# --- –§–£–ù–ö–¶–ò–Ø –¢–û–ö–ï–ù–ò–ó–ê–¶–ò–ò ---\n",
    "# ==============================================================================\n",
    "# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å tiktoken –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "# –ï—Å–ª–∏ tiktoken –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤.\n",
    "try:\n",
    "    import tiktoken\n",
    "    ENCODER = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    def tokenize_text(text: str) -> int:\n",
    "        \"\"\"–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ —Å –ø–æ–º–æ—â—å—é tiktoken.\"\"\"\n",
    "        return len(ENCODER.encode(text))\n",
    "    logger.info(\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è tiktoken –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\")\n",
    "except ImportError:\n",
    "    logger.warning(\"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'tiktoken' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤.\")\n",
    "    def tokenize_text(text: str) -> int:\n",
    "        \"\"\"–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ –∫–∞–∫ –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤.\"\"\"\n",
    "        return len(text.split())\n",
    "    \n",
    "# --- –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê ---\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_token_length_histogram():\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤.\n",
    "    –ß–∏—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ OUTPUT_DATASET_FILE, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É.\n",
    "    \"\"\"\n",
    "    token_lengths = []\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    if not os.path.exists(OUTPUT_DATASET_FILE):\n",
    "        logger.error(f\"–§–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞ '{OUTPUT_DATASET_FILE}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –±—ã–ª —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.\")\n",
    "        return\n",
    "\n",
    "    logger.info(f\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ '{OUTPUT_DATASET_FILE}' –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤...\")\n",
    "    try:\n",
    "        with open(OUTPUT_DATASET_FILE, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    # –û–∂–∏–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "                    if \"messages\" in entry and isinstance(entry[\"messages\"], list) and len(entry[\"messages\"]) == 2:\n",
    "                        user_content = entry[\"messages\"][0].get(\"content\", \"\")\n",
    "                        assistant_content = entry[\"messages\"][1].get(\"content\", \"\")\n",
    "                        \n",
    "                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—â–µ–π –¥–ª–∏–Ω—ã\n",
    "                        full_text = user_content + \" \" + assistant_content\n",
    "                        token_count = tokenize_text(full_text)\n",
    "                        token_lengths.append(token_count)\n",
    "                    else:\n",
    "                        logger.warning(f\"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–µ: {line.strip()}. –ü—Ä–æ–ø—É—Å–∫–∞—é.\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.warning(f\"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Å—Ç—Ä–æ–∫–µ: {line.strip()}. –ü—Ä–æ–ø—É—Å–∫–∞—é. –û—à–∏–±–∫–∞: {e}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏: {line.strip()}. –ü—Ä–æ–ø—É—Å–∫–∞—é. –û—à–∏–±–∫–∞: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ '{OUTPUT_DATASET_FILE}': {e}\")\n",
    "        return\n",
    "\n",
    "    if not token_lengths:\n",
    "        logger.warning(\"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤. –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.\")\n",
    "        return\n",
    "\n",
    "    logger.info(f\"–°–æ–±—Ä–∞–Ω–æ {len(token_lengths)} –¥–ª–∏–Ω —Ç–æ–∫–µ–Ω–æ–≤. –°–æ–∑–¥–∞–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã...\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã\n",
    "    plt.figure(figsize=(12, 7)) # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏\n",
    "    \n",
    "    num_bins = min(50, int(np.sqrt(len(token_lengths)))) if len(token_lengths) > 0 else 10\n",
    "    \n",
    "    plt.hist(token_lengths, bins=num_bins, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ø–æ–¥–ø–∏—Å–∏ –æ—Å–µ–π\n",
    "    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–æ–∫–µ–Ω–∞—Ö', fontsize=16)\n",
    "    plt.xlabel('–î–ª–∏–Ω–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö', fontsize=12)\n",
    "    plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤', fontsize=12)\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ—Ç–∫—É –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏–∏ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –º–µ–¥–∏–∞–Ω—ã\n",
    "    mean_length = np.mean(token_lengths)\n",
    "    median_length = np.median(token_lengths)\n",
    "    plt.axvline(mean_length, color='r', linestyle='dashed', linewidth=1.5, label=f'–°—Ä–µ–¥–Ω–µ–µ: {mean_length:.2f}')\n",
    "    plt.axvline(median_length, color='g', linestyle='dashed', linewidth=1.5, label=f'–ú–µ–¥–∏–∞–Ω–∞: {median_length:.2f}')\n",
    "    plt.legend() # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ª–µ–≥–µ–Ω–¥—É –¥–ª—è –ª–∏–Ω–∏–π —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –º–µ–¥–∏–∞–Ω—ã\n",
    "\n",
    "    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –≤ —Ñ–∞–π–ª\n",
    "    plt.savefig(HISTOGRAM_OUTPUT_FILE)\n",
    "    logger.info(f\"–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ '{HISTOGRAM_OUTPUT_FILE}'\")\n",
    "    logger.info(\"–ü—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞ –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_token_length_histogram()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc3d688",
   "metadata": {},
   "source": [
    "–í—ã–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b793c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"–í–∞—à —Ç–æ–∫–µ–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049836e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –≤–∞—à–∏–º —Å–∫—Ä–∏–ø—Ç–æ–º\n",
    "dataset_file_path = \"qwen3_adaptive_reasoning_dataset.jsonl\"\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ JSONL —Ñ–∞–π–ª–∞\n",
    "my_dataset = load_dataset('json', data_files=dataset_file_path, split=\"train\")\n",
    "\n",
    "# –£–∫–∞–∂–∏—Ç–µ —Å–≤–æ–π username –Ω–∞ Hugging Face –∏ –∂–µ–ª–∞–µ–º–æ–µ –∏–º—è –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "repo_id = \"–≤–∞—à_username/qwen3_adaptive_reasoning_dataset\"\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ Hugging Face Hub\n",
    "my_dataset.push_to_hub(repo_id)\n",
    "\n",
    "print(f\"–î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ Hugging Face Hub –ø–æ –∞–¥—Ä–µ—Å—É: https://huggingface.co/datasets/{repo_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
